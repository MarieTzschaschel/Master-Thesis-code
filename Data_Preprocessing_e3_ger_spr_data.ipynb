{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing - Creation of the final data frame for data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document contains the code for the item creation corresponding to the master thesis \"...\". \n",
    "\n",
    "The research question of the thesis is: Does the similarity of the first three noun phrase antecedents of double embedded sentences have an effect on the reading times of grammatical and ungrammatical double embedded sentences?\n",
    "\n",
    "To examine this question the self-paced-reading (SPR) and eye-tracking data of Vasishth et al. (2010) are examined. The similarity of the three noun phrase antecedents is calculated with the machine learning model Word2vec for each sentence. A linear mixed model with varying intercepts for subjects is fitted that measures the effect of the interaction between the similarity and the grammaticality of the sentences.\n",
    "In the following paragraphs the exact procedure for the creation of items as well as the actual code of item creation is presented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End product of this notebook: A data frame that contains the subject ID, the sentence number, the condition of the sentence, the reading time of the post V1 region (log transformed) and the corresponding similarity value (centred). The data was empirically collected for the Vasishth et al. (2010) study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, the required packages have to be downloaded. Pandas and numpy are both libraries that provide functions for Python, enabling the user to deal with data or mathematical structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the data corresponding to the first German SPR experiment of the Vasishth et al. (2010) study is uploaded into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Sentence_Number</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Word_Position</th>\n",
       "      <th>Word</th>\n",
       "      <th>RT</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Grammaticality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>inter</td>\n",
       "      <td>10</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>Der_Pianist,</td>\n",
       "      <td>957</td>\n",
       "      <td>similar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>inter</td>\n",
       "      <td>10</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>den</td>\n",
       "      <td>823</td>\n",
       "      <td>similar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>inter</td>\n",
       "      <td>10</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>der_Cellist,</td>\n",
       "      <td>1456</td>\n",
       "      <td>similar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>inter</td>\n",
       "      <td>10</td>\n",
       "      <td>c</td>\n",
       "      <td>4</td>\n",
       "      <td>den</td>\n",
       "      <td>1057</td>\n",
       "      <td>similar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>inter</td>\n",
       "      <td>10</td>\n",
       "      <td>c</td>\n",
       "      <td>5</td>\n",
       "      <td>der_Hausmeister</td>\n",
       "      <td>1415</td>\n",
       "      <td>similar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>9</td>\n",
       "      <td>inter</td>\n",
       "      <td>12</td>\n",
       "      <td>d</td>\n",
       "      <td>4</td>\n",
       "      <td>den</td>\n",
       "      <td>507</td>\n",
       "      <td>dissimilar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4467</th>\n",
       "      <td>9</td>\n",
       "      <td>inter</td>\n",
       "      <td>12</td>\n",
       "      <td>d</td>\n",
       "      <td>5</td>\n",
       "      <td>der_Zuschauer</td>\n",
       "      <td>557</td>\n",
       "      <td>dissimilar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4468</th>\n",
       "      <td>9</td>\n",
       "      <td>inter</td>\n",
       "      <td>12</td>\n",
       "      <td>d</td>\n",
       "      <td>6</td>\n",
       "      <td>bewunderte,</td>\n",
       "      <td>619</td>\n",
       "      <td>dissimilar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4469</th>\n",
       "      <td>9</td>\n",
       "      <td>inter</td>\n",
       "      <td>12</td>\n",
       "      <td>d</td>\n",
       "      <td>7</td>\n",
       "      <td>beobachtete</td>\n",
       "      <td>1108</td>\n",
       "      <td>dissimilar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4470</th>\n",
       "      <td>9</td>\n",
       "      <td>inter</td>\n",
       "      <td>12</td>\n",
       "      <td>d</td>\n",
       "      <td>8</td>\n",
       "      <td>den_Einlasser.</td>\n",
       "      <td>1119</td>\n",
       "      <td>dissimilar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4471 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Subject_ID Experiment  Sentence_Number Condition  Word_Position  \\\n",
       "0             10      inter               10         c              1   \n",
       "1             10      inter               10         c              2   \n",
       "2             10      inter               10         c              3   \n",
       "3             10      inter               10         c              4   \n",
       "4             10      inter               10         c              5   \n",
       "...          ...        ...              ...       ...            ...   \n",
       "4466           9      inter               12         d              4   \n",
       "4467           9      inter               12         d              5   \n",
       "4468           9      inter               12         d              6   \n",
       "4469           9      inter               12         d              7   \n",
       "4470           9      inter               12         d              8   \n",
       "\n",
       "                 Word    RT  Similarity Grammaticality  \n",
       "0        Der_Pianist,   957     similar  ungrammatical  \n",
       "1                 den   823     similar  ungrammatical  \n",
       "2        der_Cellist,  1456     similar  ungrammatical  \n",
       "3                 den  1057     similar  ungrammatical  \n",
       "4     der_Hausmeister  1415     similar  ungrammatical  \n",
       "...               ...   ...         ...            ...  \n",
       "4466              den   507  dissimilar  ungrammatical  \n",
       "4467    der_Zuschauer   557  dissimilar  ungrammatical  \n",
       "4468      bewunderte,   619  dissimilar  ungrammatical  \n",
       "4469      beobachtete  1108  dissimilar  ungrammatical  \n",
       "4470   den_Einlasser.  1119  dissimilar  ungrammatical  \n",
       "\n",
       "[4471 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('e3_de_spr_data_single_space.txt', sep=' ', names=['Subject_ID', 'Experiment', 'Sentence_Number', 'Condition', 'Word_Position','Word', 'RT','Similarity', 'Grammaticality'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of relevant data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of data points are not needed for the purpose of this study. Only the post V1 region of the 'gug' condition (the experimental condition) is needed. The relevant data has to be extracted of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Sentence_Number</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Word_Position</th>\n",
       "      <th>Word</th>\n",
       "      <th>RT</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Grammaticality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Subject_ID, Experiment, Sentence_Number, Condition, Word_Position, Word, RT, Similarity, Grammaticality]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the experimental condition 'gug'\n",
    "df_gug = df[df.Experiment=='gug']\n",
    "df_gug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All words of the \"gug\" condition are now extracted and stored in a new data frame called df_gug. \n",
    "Since only the post V1 region is relevant for the data analysis the relevant rows, corresponding to the post V1 region, have to be extracted from the data frame df_gug. The post V1 region is always the second last word of every sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to get the second last word of every sentence:\n",
    "Since all sentences differ in their length, it is not directly possible to access the second last word of each sentence. We therefore try first to find out the word positions of the last words of all sentences to be able to extract the second last words.\n",
    "\n",
    "Our procedure to find the last word of every sentence works as follows: We start by finding the words that occur with a dot since every sentence ends with a dot. Therefore, the most straight forward way to find out where sentences end is to find out the positions of these dots. To do so, we create a Boolean series that gives us a TRUE when a dot occurs after a word and a FALSE when this is not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "4466    False\n",
       "4467    False\n",
       "4468    False\n",
       "4469    False\n",
       "4470     True\n",
       "Name: Word, Length: 4471, dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_word = df.Word.apply(lambda x: '.' in x)\n",
    "last_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create an array 'index_last_word' that extracts the words' numbers that have a TRUE as output in our Boolean series (thus, that occur with a dot in the end). As a consequence, we have the indices of all last words of all sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_last_word = np.where(last_word)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't need the last word but the second last word, we subtract 1 from each index and store the numbers in an array index_second_last. We then extract all words that correspond to the numbers in the array index_second_last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of second last word\n",
    "index_second_last = index_last_word -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Sentence_Number</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Word_Position</th>\n",
       "      <th>Word</th>\n",
       "      <th>RT</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Grammaticality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>inter</td>\n",
       "      <td>10</td>\n",
       "      <td>c</td>\n",
       "      <td>7</td>\n",
       "      <td>ersetzte</td>\n",
       "      <td>762</td>\n",
       "      <td>similar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>inter</td>\n",
       "      <td>11</td>\n",
       "      <td>d</td>\n",
       "      <td>7</td>\n",
       "      <td>verarztete</td>\n",
       "      <td>792</td>\n",
       "      <td>dissimilar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>inter</td>\n",
       "      <td>9</td>\n",
       "      <td>b</td>\n",
       "      <td>8</td>\n",
       "      <td>bestahl</td>\n",
       "      <td>598</td>\n",
       "      <td>dissimilar</td>\n",
       "      <td>grammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10</td>\n",
       "      <td>inter</td>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>8</td>\n",
       "      <td>hasste</td>\n",
       "      <td>752</td>\n",
       "      <td>similar</td>\n",
       "      <td>grammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10</td>\n",
       "      <td>inter</td>\n",
       "      <td>6</td>\n",
       "      <td>c</td>\n",
       "      <td>7</td>\n",
       "      <td>beschuldigte</td>\n",
       "      <td>720</td>\n",
       "      <td>similar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>9</td>\n",
       "      <td>inter</td>\n",
       "      <td>4</td>\n",
       "      <td>d</td>\n",
       "      <td>7</td>\n",
       "      <td>hasste</td>\n",
       "      <td>558</td>\n",
       "      <td>dissimilar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444</th>\n",
       "      <td>9</td>\n",
       "      <td>inter</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>8</td>\n",
       "      <td>besuchte</td>\n",
       "      <td>557</td>\n",
       "      <td>similar</td>\n",
       "      <td>grammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>9</td>\n",
       "      <td>inter</td>\n",
       "      <td>8</td>\n",
       "      <td>d</td>\n",
       "      <td>7</td>\n",
       "      <td>beschimpfte</td>\n",
       "      <td>752</td>\n",
       "      <td>dissimilar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>9</td>\n",
       "      <td>inter</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>8</td>\n",
       "      <td>verärgerte</td>\n",
       "      <td>680</td>\n",
       "      <td>dissimilar</td>\n",
       "      <td>grammatical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4469</th>\n",
       "      <td>9</td>\n",
       "      <td>inter</td>\n",
       "      <td>12</td>\n",
       "      <td>d</td>\n",
       "      <td>7</td>\n",
       "      <td>beobachtete</td>\n",
       "      <td>1108</td>\n",
       "      <td>dissimilar</td>\n",
       "      <td>ungrammatical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>526 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Subject_ID Experiment  Sentence_Number Condition  Word_Position  \\\n",
       "6             10      inter               10         c              7   \n",
       "14            10      inter               11         d              7   \n",
       "23            10      inter                9         b              8   \n",
       "32            10      inter                4         a              8   \n",
       "40            10      inter                6         c              7   \n",
       "...          ...        ...              ...       ...            ...   \n",
       "4435           9      inter                4         d              7   \n",
       "4444           9      inter                5         a              8   \n",
       "4452           9      inter                8         d              7   \n",
       "4461           9      inter                2         b              8   \n",
       "4469           9      inter               12         d              7   \n",
       "\n",
       "              Word    RT  Similarity Grammaticality  \n",
       "6         ersetzte   762     similar  ungrammatical  \n",
       "14      verarztete   792  dissimilar  ungrammatical  \n",
       "23         bestahl   598  dissimilar    grammatical  \n",
       "32          hasste   752     similar    grammatical  \n",
       "40    beschuldigte   720     similar  ungrammatical  \n",
       "...            ...   ...         ...            ...  \n",
       "4435        hasste   558  dissimilar  ungrammatical  \n",
       "4444      besuchte   557     similar    grammatical  \n",
       "4452   beschimpfte   752  dissimilar  ungrammatical  \n",
       "4461    verärgerte   680  dissimilar    grammatical  \n",
       "4469   beobachtete  1108  dissimilar  ungrammatical  \n",
       "\n",
       "[526 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_last_word = df.iloc[index_second_last]\n",
    "second_last_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The similarity values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we first import the nouns with two conditions, the similar and the contrast condition, and their corresponding similarity values. Next the concept of centred similarity is explained and carried out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now import the similarity values and store them into a data frame called Simval_df. \n",
    "We have two similarity values for each sentence. One similarity value is for the similar condition with three animate noun phrases, one for the contrast condition with two animate nouns and one inanimate noun in the middle. \n",
    "The similarity values are the mean similarity of the three nouns respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_Number</th>\n",
       "      <th>Similar_condition</th>\n",
       "      <th>Contrast_condition</th>\n",
       "      <th>SimVal_Similar</th>\n",
       "      <th>SimVal_Contrast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>('Anwalt', 'Zeuge', 'Spion')</td>\n",
       "      <td>('Anwalt', 'Saebel', 'Spion')</td>\n",
       "      <td>0.490121</td>\n",
       "      <td>0.217141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>('Beamte', 'Buerokrat', 'Besucher')</td>\n",
       "      <td>('Beamte', 'Tisch', 'Besucher')</td>\n",
       "      <td>0.199580</td>\n",
       "      <td>0.243456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>('Braeutigam', 'Schwiegervater', 'Musiker')</td>\n",
       "      <td>('Braeutigam', 'Bilderrahmen', 'Musiker')</td>\n",
       "      <td>0.413416</td>\n",
       "      <td>0.310512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>('Bruder', 'Cousin', 'Bauer')</td>\n",
       "      <td>('Bruder', 'Schmuck', 'Bauer')</td>\n",
       "      <td>0.625180</td>\n",
       "      <td>0.218115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>('Zauberer', 'Akrobat', 'Zuschauer')</td>\n",
       "      <td>('Zauberer', 'Hut', 'Zuschauer')</td>\n",
       "      <td>0.456369</td>\n",
       "      <td>0.308386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>('Einbrecher', 'Dieb', 'Mann')</td>\n",
       "      <td>('Einbrecher', 'Stein', 'Mann')</td>\n",
       "      <td>0.721395</td>\n",
       "      <td>0.321455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>('Neurotiker', 'Exzentriker', 'Psychiater')</td>\n",
       "      <td>('Neurotiker', 'Dolch', 'Psychiater')</td>\n",
       "      <td>0.449083</td>\n",
       "      <td>0.226837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>('Arbeiter', 'Monteur', 'Vorarbeiter')</td>\n",
       "      <td>('Arbeiter', 'Eimer', 'Vorarbeiter')</td>\n",
       "      <td>0.601547</td>\n",
       "      <td>0.379001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>('Banker', 'Kreditgeber', 'Kunde')</td>\n",
       "      <td>('Banker', 'Geldautomat', 'Kunde')</td>\n",
       "      <td>0.539573</td>\n",
       "      <td>0.435449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>('Pianist', 'Cellist', 'Hausmeister')</td>\n",
       "      <td>('Pianist', 'Ball', 'Hausmeister')</td>\n",
       "      <td>0.578632</td>\n",
       "      <td>0.254380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>('Anwohner', 'Wanderer', 'Pfoertner')</td>\n",
       "      <td>('Anwohner', 'Stuhl', 'Pfoertner')</td>\n",
       "      <td>0.330717</td>\n",
       "      <td>0.335074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>('Taenzer', 'Artist', 'Zuschauer')</td>\n",
       "      <td>('Taenzer', 'Schuh', 'Zuschauer')</td>\n",
       "      <td>0.377276</td>\n",
       "      <td>0.316833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence_Number                            Similar_condition  \\\n",
       "0                 0                 ('Anwalt', 'Zeuge', 'Spion')   \n",
       "1                 1          ('Beamte', 'Buerokrat', 'Besucher')   \n",
       "2                 2  ('Braeutigam', 'Schwiegervater', 'Musiker')   \n",
       "3                 3                ('Bruder', 'Cousin', 'Bauer')   \n",
       "4                 4         ('Zauberer', 'Akrobat', 'Zuschauer')   \n",
       "5                 5               ('Einbrecher', 'Dieb', 'Mann')   \n",
       "6                 6  ('Neurotiker', 'Exzentriker', 'Psychiater')   \n",
       "7                 7       ('Arbeiter', 'Monteur', 'Vorarbeiter')   \n",
       "8                 8           ('Banker', 'Kreditgeber', 'Kunde')   \n",
       "9                 9        ('Pianist', 'Cellist', 'Hausmeister')   \n",
       "10               10        ('Anwohner', 'Wanderer', 'Pfoertner')   \n",
       "11               11           ('Taenzer', 'Artist', 'Zuschauer')   \n",
       "\n",
       "                           Contrast_condition  SimVal_Similar  SimVal_Contrast  \n",
       "0               ('Anwalt', 'Saebel', 'Spion')        0.490121         0.217141  \n",
       "1             ('Beamte', 'Tisch', 'Besucher')        0.199580         0.243456  \n",
       "2   ('Braeutigam', 'Bilderrahmen', 'Musiker')        0.413416         0.310512  \n",
       "3              ('Bruder', 'Schmuck', 'Bauer')        0.625180         0.218115  \n",
       "4            ('Zauberer', 'Hut', 'Zuschauer')        0.456369         0.308386  \n",
       "5             ('Einbrecher', 'Stein', 'Mann')        0.721395         0.321455  \n",
       "6       ('Neurotiker', 'Dolch', 'Psychiater')        0.449083         0.226837  \n",
       "7        ('Arbeiter', 'Eimer', 'Vorarbeiter')        0.601547         0.379001  \n",
       "8          ('Banker', 'Geldautomat', 'Kunde')        0.539573         0.435449  \n",
       "9          ('Pianist', 'Ball', 'Hausmeister')        0.578632         0.254380  \n",
       "10         ('Anwohner', 'Stuhl', 'Pfoertner')        0.330717         0.335074  \n",
       "11          ('Taenzer', 'Schuh', 'Zuschauer')        0.377276         0.316833  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Simval_df = pd.read_csv('df_SimilarityValues_ger.csv', sep=',', names=['Sentence_Number', 'Similar_condition', 'Contrast_condition', 'SimVal_Similar', 'SimVal_Contrast'])\n",
    "Simval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of centred similarity is an equivalent to the sum contrast coding that will be used for the data analysis later on. \n",
    "In the sum contrast coding each data point is coded as a function of the overall mean of all data points.\n",
    "For the sum contrast coding for the condition of grammaticality we have +1 for grammatical and -1 for ungrammatical sentences.\n",
    "For the examination of the research question we have to carry out an interaction analysis to see the impact of the similarity values (hence the condition of similarity) on the condition of grammaticality. \n",
    "For this purpose, the similarity values have to be adapted to the sum contrast coding concept. This is done by subtracting the mean similarity value from each individual similarity value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we calculate the mean similarity value from the similar and the contrast condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Simval_Similar = list(Simval_df['SimVal_Similar'])\n",
    "Simval_Contrast = list(Simval_df['SimVal_Contrast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_sim = Simval_Similar + Simval_Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38956377375870943"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sim = np.mean(added_sim)\n",
    "mean_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to subtract the mean from each similarity value.\n",
    "\n",
    "This is done with a for loop that loops over the Simval_Similar list (containing all similarity values corresponding to the noun pairs of the similar group) or Simval_Contrast list (containing all similarity values corresponding to the noun pairs of the contrast group). For each value of the list, we subtract the mean from that value and store the result in a list called Centred_simval_similar or Centred_simval_contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10055741202086205, -0.18998370785266158, 0.023852135054767132, 0.23561581503599882, 0.06680520903319115, 0.3318315101787448, 0.05951962899416685, 0.21198287140578032, 0.15000962745398283, 0.1890681041404605, -0.05884656775742775, -0.0122876511886717]\n"
     ]
    }
   ],
   "source": [
    "Centred_simval_similar = []\n",
    "for value in Simval_Similar:\n",
    "    Centred_simval_similar.append(value - mean_sim)\n",
    "print(Centred_simval_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.17242250312119722, -0.14610760379582644, -0.07905130553990602, -0.17144855577498674, -0.08117786515504122, -0.06810848880559206, -0.16272658575326204, -0.010562394745647907, 0.04588540922850365, -0.13518370408564806, -0.05449009407311678, -0.07273069489747286]\n"
     ]
    }
   ],
   "source": [
    "Centred_simval_contrast = []\n",
    "for value in Simval_Contrast:\n",
    "    Centred_simval_contrast.append(value - mean_sim)\n",
    "print(Centred_simval_contrast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our end data frame we need log transformed reading times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logRT = list(np.log(second_last_word['RT']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section is about merging the correct similarity value to its corresponding sentence number,  condition and reading time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do that, we first create a data frame containing all the relevant information for our end data frame, except of the similarity values and the contrast coding for the condition of grammaticality (+1 and -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Sentence_Number</th>\n",
       "      <th>Condition</th>\n",
       "      <th>logRT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>c</td>\n",
       "      <td>6.635947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>d</td>\n",
       "      <td>6.674561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>b</td>\n",
       "      <td>6.393591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>6.622736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>c</td>\n",
       "      <td>6.579251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>d</td>\n",
       "      <td>6.324359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>6.322565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>d</td>\n",
       "      <td>6.622736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>6.522093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>d</td>\n",
       "      <td>7.010312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>526 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject_ID  Sentence_Number Condition     logRT\n",
       "0            10               10         c  6.635947\n",
       "1            10               11         d  6.674561\n",
       "2            10                9         b  6.393591\n",
       "3            10                4         a  6.622736\n",
       "4            10                6         c  6.579251\n",
       "..          ...              ...       ...       ...\n",
       "521           9                4         d  6.324359\n",
       "522           9                5         a  6.322565\n",
       "523           9                8         d  6.622736\n",
       "524           9                2         b  6.522093\n",
       "525           9               12         d  7.010312\n",
       "\n",
       "[526 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_WithoutSim = pd.DataFrame(list(zip(second_last_word.Subject_ID, second_last_word.Sentence_Number, second_last_word.Condition, logRT)),\n",
    "                            columns = ['Subject_ID', 'Sentence_Number', 'Condition', 'logRT'])\n",
    "df_WithoutSim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame we need for the statistical analysis would have one more column containing the centred similarity values. We have two similarity values for all sentences (1-16). Condition a and c need the similarity values of the similar condition, condition b and d need the similarity value of the contrast condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do that, we write a for loop that loops over the list “Sentence_Number” of our data frame “df_WithoutSim”. Note that the list “Sentence_Number” does not only contain the numbers from 1 to 16! It has length 800 and contains the sentence numbers that correspond to the sentences that have been read by a specific participant. The ‘iterater’ variable starts to count from zero until the end of a list. In other words, it assigns an index, stating at zero until the end, for every time we move on to the next item of our for loop. The variable ‘i’ refers to the entry at a specific point in the list “Sentence_Number”. The function enumerate makes the for loop loop through the whole list “Sentence_Number”.  Assume we start at the first entry in Sentence_Number. The first entry is the sentence 14, read by participant 1. Thus, our iterater would start counting at zero and the variable ‘i’ would get 14. Before jumping to the next entry, we now want to know which condition this entry has. This is important in order to assign the correct similarity value to that entry. Therefore, we look at the entry in the “Condition” column of our data frame “df_WithoutSim” in the same row (in our example row zero). If the entry is either ‘a’ or ‘c’ (similar condition) we append the centred similarity value for the similar group of that same sentence in an empty list called “Similarity_Values_dat”. In our example we would append the centred similarity value for the contrast condition of sentence 14 ~-0.212, since the condition in the first entry of the data frame is 'b'. Thereby, we have to take the entry i-1 of the “Centred_simval_similar” list. We have to take i-1 since Python starts counting at zero. ‘i’ is the correct sentence number. In our example i=14. In the “Centred_simval_similar” list we have all the similarity values for all sentences in the correct order, starting from zero to fifteen. If we want to add the similarity value of the fourteenth sentence, we have to take the thirteenth entry of the “Centred_simval_similar” list. If the condition is not ‘a’ or ‘c’ (meaning it has to be ‘b’ or ‘d’) we want to add the corresponding contrast centred similarity value. We then take the i-1th entry of the “Centered_simval_contrast” list and append it to the “Similarity_Values_dat” list. After that, enumerate makes us loop to the next entry of “Sentence_Number” etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1890681041404605, -0.05449009407311678, 0.04588540922850365, 0.23561581503599882, 0.3318315101787448, -0.0122876511886717, -0.17242250312119722, 0.21198287140578032, -0.07905130553990602, -0.18998370785266158, -0.16272658575326204, -0.08117786515504122, -0.05449009407311678, -0.08117786515504122, -0.0122876511886717, -0.16272658575326204, 0.04588540922850365, 0.23561581503599882, 0.3318315101787448, 0.21198287140578032, -0.17242250312119722, 0.1890681041404605, -0.18998370785266158, -0.07905130553990602, -0.13518370408564806, 0.06680520903319115, -0.010562394745647907, 0.05951962899416685, -0.05884656775742775, -0.17144855577498674, -0.06810848880559206, 0.10055741202086205, -0.14610760379582644, -0.07273069489747286, 0.15000962745398283, 0.023852135054767132, 0.04588540922850365, 0.21198287140578032, -0.17242250312119722, 0.3318315101787448, 0.1890681041404605, -0.16272658575326204, -0.18998370785266158, -0.05449009407311678, 0.23561581503599882, -0.07905130553990602, -0.0122876511886717, -0.08117786515504122, -0.17144855577498674, -0.14610760379582644, -0.05884656775742775, 0.15000962745398283, -0.010562394745647907, 0.023852135054767132, -0.06810848880559206, 0.10055741202086205, -0.07273069489747286, 0.05951962899416685, -0.13518370408564806, 0.06680520903319115, -0.07905130553990602, -0.05449009407311678, -0.17242250312119722, -0.18998370785266158, 0.21198287140578032, -0.0122876511886717, 0.04588540922850365, 0.3318315101787448, 0.23561581503599882, 0.1890681041404605, -0.08117786515504122, -0.16272658575326204, 0.023852135054767132, -0.05884656775742775, -0.07273069489747286, 0.15000962745398283, -0.13518370408564806, -0.06810848880559206, -0.14610760379582644, 0.10055741202086205, 0.06680520903319115, 0.05951962899416685, -0.010562394745647907, -0.17144855577498674, 0.1890681041404605, -0.17242250312119722, -0.07905130553990602, -0.05449009407311678, -0.08117786515504122, 0.21198287140578032, -0.0122876511886717, 0.23561581503599882, -0.18998370785266158, 0.04588540922850365, 0.3318315101787448, -0.16272658575326204, -0.010562394745647907, 0.06680520903319115, -0.13518370408564806, -0.17144855577498674, 0.15000962745398283, 0.10055741202086205, 0.05951962899416685, -0.14610760379582644, -0.05884656775742775, -0.07273069489747286, -0.06810848880559206, 0.023852135054767132, 0.04588540922850365, -0.16272658575326204, -0.07905130553990602, -0.08117786515504122, -0.05449009407311678, 0.21198287140578032, -0.18998370785266158, 0.23561581503599882, 0.3318315101787448, -0.0122876511886717, -0.17242250312119722, 0.1890681041404605, -0.14610760379582644, 0.10055741202086205, 0.15000962745398283, -0.13518370408564806, 0.06680520903319115, -0.010562394745647907, -0.17144855577498674, -0.06810848880559206, -0.07273069489747286, -0.05884656775742775, 0.023852135054767132, 0.05951962899416685, 0.10055741202086205, -0.06810848880559206, -0.05884656775742775, -0.07273069489747286, -0.13518370408564806, 0.06680520903319115, -0.010562394745647907, 0.05951962899416685, -0.14610760379582644, 0.023852135054767132, -0.17144855577498674, 0.15000962745398283, -0.16272658575326204, 0.04588540922850365, 0.3318315101787448, -0.05449009407311678, -0.08117786515504122, 0.23561581503599882, -0.07905130553990602, 0.1890681041404605, 0.21198287140578032, -0.18998370785266158, -0.17242250312119722, -0.0122876511886717, 0.023852135054767132, -0.13518370408564806, -0.14610760379582644, -0.010562394745647907, 0.10055741202086205, 0.06680520903319115, 0.05951962899416685, 0.15000962745398283, -0.05884656775742775, -0.06810848880559206, -0.17144855577498674, -0.07273069489747286, 0.3318315101787448, 0.1890681041404605, -0.05449009407311678, -0.18998370785266158, -0.0122876511886717, 0.04588540922850365, -0.16272658575326204, 0.23561581503599882, -0.08117786515504122, -0.17242250312119722, -0.07905130553990602, 0.21198287140578032, 0.10055741202086205, -0.17144855577498674, 0.06680520903319115, -0.13518370408564806, -0.07273069489747286, 0.023852135054767132, -0.06810848880559206, 0.15000962745398283, -0.14610760379582644, 0.05951962899416685, -0.05884656775742775, -0.010562394745647907, 0.3318315101787448, 0.04588540922850365, -0.16272658575326204, 0.23561581503599882, 0.1890681041404605, -0.0122876511886717, -0.05449009407311678, -0.08117786515504122, -0.07905130553990602, 0.21198287140578032, -0.17242250312119722, -0.18998370785266158, -0.06810848880559206, -0.05884656775742775, 0.10055741202086205, -0.14610760379582644, -0.07273069489747286, 0.023852135054767132, -0.010562394745647907, 0.06680520903319115, 0.05951962899416685, -0.13518370408564806, -0.08117786515504122, 0.04588540922850365, -0.07905130553990602, -0.16272658575326204, 0.21198287140578032, 0.3318315101787448, -0.0122876511886717, 0.1890681041404605, -0.17242250312119722, 0.23561581503599882, -0.05449009407311678, -0.18998370785266158, -0.05884656775742775, 0.06680520903319115, -0.13518370408564806, -0.07273069489747286, -0.06810848880559206, 0.15000962745398283, 0.10055741202086205, -0.14610760379582644, -0.17144855577498674, 0.023852135054767132, 0.05951962899416685, -0.010562394745647907, -0.07905130553990602, -0.05449009407311678, 0.21198287140578032, -0.16272658575326204, 0.3318315101787448, -0.18998370785266158, 0.23561581503599882, -0.17242250312119722, -0.0122876511886717, 0.04588540922850365, -0.08117786515504122, 0.1890681041404605, 0.10055741202086205, -0.07273069489747286, 0.15000962745398283, -0.17144855577498674, -0.010562394745647907, -0.13518370408564806, -0.14610760379582644, 0.05951962899416685, -0.05884656775742775, 0.06680520903319115, -0.06810848880559206, 0.023852135054767132, 0.3318315101787448, 0.1890681041404605, -0.08117786515504122, -0.16272658575326204, -0.05449009407311678, 0.04588540922850365, -0.07905130553990602, 0.23561581503599882, -0.17242250312119722, -0.0122876511886717, 0.21198287140578032, -0.18998370785266158, -0.06810848880559206, -0.17144855577498674, -0.07273069489747286, 0.10055741202086205, -0.05884656775742775, 0.05951962899416685, 0.023852135054767132, -0.13518370408564806, 0.06680520903319115, -0.14610760379582644, 0.15000962745398283, -0.010562394745647907, -0.17242250312119722, -0.07905130553990602, -0.16272658575326204, -0.0122876511886717, 0.21198287140578032, -0.18998370785266158, -0.05449009407311678, 0.23561581503599882, 0.04588540922850365, -0.08117786515504122, 0.1890681041404605, 0.3318315101787448, -0.010562394745647907, -0.14610760379582644, 0.023852135054767132, 0.06680520903319115, 0.15000962745398283, -0.05884656775742775, -0.06810848880559206, -0.13518370408564806, -0.07273069489747286, -0.17144855577498674, 0.10055741202086205, 0.05951962899416685, -0.18998370785266158, -0.16272658575326204, 0.23561581503599882, 0.21198287140578032, -0.0122876511886717, -0.17242250312119722, 0.04588540922850365, -0.05449009407311678, 0.3318315101787448, 0.1890681041404605, -0.08117786515504122, -0.07905130553990602, -0.06810848880559206, -0.17144855577498674, 0.15000962745398283, -0.05884656775742775, 0.06680520903319115, -0.14610760379582644, -0.13518370408564806, 0.10055741202086205, -0.010562394745647907, 0.05951962899416685, -0.07273069489747286, 0.023852135054767132, -0.07905130553990602, 0.3318315101787448, -0.17242250312119722, -0.0122876511886717, -0.18998370785266158, 0.23561581503599882, 0.04588540922850365, -0.08117786515504122, 0.1890681041404605, -0.16272658575326204, 0.21198287140578032, -0.05449009407311678, -0.14610760379582644, -0.17144855577498674, -0.010562394745647907, 0.06680520903319115, -0.06810848880559206, -0.05884656775742775, 0.10055741202086205, 0.023852135054767132, -0.13518370408564806, 0.15000962745398283, -0.07273069489747286, 0.05951962899416685, -0.17242250312119722, 0.23561581503599882, -0.18998370785266158, -0.0122876511886717, 0.3318315101787448, -0.07905130553990602, -0.05449009407311678, 0.21198287140578032, 0.04588540922850365, 0.1890681041404605, -0.16272658575326204, -0.08117786515504122, -0.14610760379582644, -0.05884656775742775, -0.17144855577498674, 0.06680520903319115, 0.05951962899416685, -0.07273069489747286, -0.06810848880559206, -0.010562394745647907, -0.13518370408564806, 0.15000962745398283, 0.023852135054767132, 0.10055741202086205, -0.17242250312119722, -0.08117786515504122, -0.07905130553990602, 0.04588540922850365, -0.16272658575326204, 0.23561581503599882, 0.1890681041404605, -0.18998370785266158, 0.21198287140578032, 0.3318315101787448, -0.0122876511886717, -0.05449009407311678, -0.010562394745647907, -0.17144855577498674, -0.07273069489747286, 0.023852135054767132, -0.06810848880559206, 0.10055741202086205, -0.14610760379582644, -0.13518370408564806, 0.15000962745398283, -0.05884656775742775, 0.06680520903319115, 0.05951962899416685, 0.21198287140578032, -0.17242250312119722, 0.23561581503599882, 0.1890681041404605, -0.18998370785266158, -0.07905130553990602, 0.04588540922850365, 0.3318315101787448, -0.16272658575326204, -0.0122876511886717, -0.08117786515504122, -0.05449009407311678, -0.06810848880559206, 0.06680520903319115, 0.10055741202086205, -0.05884656775742775, 0.023852135054767132, -0.14610760379582644, -0.17144855577498674, 0.05951962899416685, -0.13518370408564806, -0.010562394745647907, 0.15000962745398283, -0.07273069489747286, -0.05449009407311678, 0.21198287140578032, -0.17242250312119722, 0.23561581503599882, -0.07905130553990602, -0.16272658575326204, 0.3318315101787448, 0.04588540922850365, -0.0122876511886717, -0.18998370785266158, 0.1890681041404605, -0.08117786515504122, -0.13518370408564806, -0.010562394745647907, -0.06810848880559206, 0.05951962899416685, -0.07273069489747286, 0.06680520903319115, -0.17144855577498674, 0.10055741202086205, -0.14610760379582644, 0.15000962745398283, -0.05884656775742775, 0.023852135054767132, -0.0122876511886717, -0.08117786515504122, 0.1890681041404605, -0.05449009407311678, -0.17242250312119722, -0.07905130553990602, -0.16272658575326204, 0.04588540922850365, 0.3318315101787448, 0.23561581503599882, -0.18998370785266158, 0.21198287140578032, 0.05951962899416685, -0.010562394745647907, -0.13518370408564806, -0.07273069489747286, -0.17144855577498674, -0.05884656775742775, -0.06810848880559206, 0.06680520903319115, 0.023852135054767132, 0.15000962745398283, 0.10055741202086205, -0.14610760379582644, -0.17242250312119722, 0.3318315101787448, -0.0122876511886717, -0.08117786515504122, -0.16272658575326204, -0.07905130553990602, -0.18998370785266158, 0.04588540922850365, -0.05449009407311678, 0.21198287140578032, 0.1890681041404605, 0.23561581503599882, 0.10055741202086205, 0.023852135054767132, -0.06810848880559206, -0.07273069489747286, 0.06680520903319115, 0.15000962745398283, -0.17144855577498674, -0.05884656775742775, -0.010562394745647907, 0.05951962899416685, -0.13518370408564806, -0.14610760379582644, 0.23561581503599882, 0.1890681041404605, -0.07905130553990602, -0.17242250312119722, 0.21198287140578032, -0.0122876511886717, -0.05449009407311678, 0.3318315101787448, -0.08117786515504122, 0.04588540922850365, -0.18998370785266158, -0.16272658575326204, -0.13518370408564806, -0.05884656775742775, 0.10055741202086205, -0.06810848880559206, 0.05951962899416685, 0.023852135054767132, 0.15000962745398283, -0.17144855577498674, 0.06680520903319115, -0.010562394745647907, -0.14610760379582644, -0.07273069489747286]\n"
     ]
    }
   ],
   "source": [
    "Similarity_Values_dat = []\n",
    "\n",
    "for iterater, i in enumerate(df_WithoutSim.Sentence_Number):\n",
    "    if df_WithoutSim.Condition[iterater] in ['a', 'c']:\n",
    "        simVal_similar = Centred_simval_similar[i-1]\n",
    "        Similarity_Values_dat.append(simVal_similar)\n",
    "    else:\n",
    "        simVal_Con = Centred_simval_contrast[i-1]\n",
    "        Similarity_Values_dat.append(simVal_Con)\n",
    "print(Similarity_Values_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final data frame for data analysis we need the grammaticality condition to be coded as + and - 1. Conditions a and b refer to grammatical sentences, condition c and d to ungrammatical sentences. We iterate over the column \"Condition\" of our data frame 'df_WithoutSim'. If the condition is equal to 'a' or 'b' we enter a 1 in the list 'Contrast_Coding', else (if condition is equal to 'c' or 'd') we enter -1 in the list. This list can later be added in the data frame in a new column called \"Contrast_coding\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, 1, -1, -1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, -1]\n"
     ]
    }
   ],
   "source": [
    "Contrast_Coding = []\n",
    "\n",
    "for cond in df_WithoutSim.Condition:\n",
    "    if cond in ['a','b']:\n",
    "        Contrast_Coding.append(1)\n",
    "    else:\n",
    "        Contrast_Coding.append(-1)\n",
    "print(Contrast_Coding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything we need to create the final data frame, thus to add a column for the contrast coding numbers and the centred similarity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Sentence_Number</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Contrast_Coding</th>\n",
       "      <th>logRT</th>\n",
       "      <th>Centered_Sim_Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>c</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.635947</td>\n",
       "      <td>0.189068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>d</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.674561</td>\n",
       "      <td>-0.054490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>6.393591</td>\n",
       "      <td>0.045885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>6.622736</td>\n",
       "      <td>0.235616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>c</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.579251</td>\n",
       "      <td>0.331832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>d</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.324359</td>\n",
       "      <td>-0.171449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>6.322565</td>\n",
       "      <td>0.066805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>d</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.622736</td>\n",
       "      <td>-0.010562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>6.522093</td>\n",
       "      <td>-0.146108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>d</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.010312</td>\n",
       "      <td>-0.072731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>526 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject_ID  Sentence_Number Condition  Contrast_Coding     logRT  \\\n",
       "0            10               10         c               -1  6.635947   \n",
       "1            10               11         d               -1  6.674561   \n",
       "2            10                9         b                1  6.393591   \n",
       "3            10                4         a                1  6.622736   \n",
       "4            10                6         c               -1  6.579251   \n",
       "..          ...              ...       ...              ...       ...   \n",
       "521           9                4         d               -1  6.324359   \n",
       "522           9                5         a                1  6.322565   \n",
       "523           9                8         d               -1  6.622736   \n",
       "524           9                2         b                1  6.522093   \n",
       "525           9               12         d               -1  7.010312   \n",
       "\n",
       "     Centered_Sim_Val  \n",
       "0            0.189068  \n",
       "1           -0.054490  \n",
       "2            0.045885  \n",
       "3            0.235616  \n",
       "4            0.331832  \n",
       "..                ...  \n",
       "521         -0.171449  \n",
       "522          0.066805  \n",
       "523         -0.010562  \n",
       "524         -0.146108  \n",
       "525         -0.072731  \n",
       "\n",
       "[526 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_WithSim = pd.DataFrame(list(zip(df_WithoutSim.Subject_ID, df_WithoutSim.Sentence_Number, df_WithoutSim.Condition, Contrast_Coding, logRT, Similarity_Values_dat)),\n",
    "                            columns = ['Subject_ID', 'Sentence_Number', 'Condition', 'Contrast_Coding','logRT', 'Centered_Sim_Val'])\n",
    "df_WithSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now ready to export the data frame for the data analysis in r\n",
    "df_WithSim.to_csv('Final_DataFrame_e3.csv', sep=',', header=False, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
